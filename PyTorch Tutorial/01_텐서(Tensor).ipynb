{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69835250-2b92-480c-be38-a35ca17ab75c",
   "metadata": {},
   "source": [
    "# [텐서(Tensor)](https://tutorials.pytorch.kr/beginner/basics/tensorqs_tutorial.html)\n",
    "\n",
    "- 텐서(Tensor)는 배열(Array)이나 행렬(Matrix)과 매우 유사하고 특별화된 자료구조이다.\n",
    "\n",
    "- PyTorch 에서는 텐서를 사용하여 모델의 입력(input)과 출력(output), 그리고 모델의 매개변수들을 부호화(encode) 할 수 있다.\n",
    "\n",
    "- 텐서는 GPU나 다른 하드웨어 가속기에서 실행할 수 있다는 점만 제외하면 Numpy의 ndarray와 유사하다.\n",
    "\n",
    "- 실제로 텐서와 Numpy 배열은 종종 동일한 내부(underly) 메모리를 공유할 수 있어, 데이터를 복사할 필요가 없다.\n",
    "\n",
    "- 또한, 텐서는 자동 미분(Automatic Differentiation)에 최적화되어 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a19aa49f-ba65-4df3-828f-d907ff3c9bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version : 1.10.2 \n",
      "\n",
      "Numpy Version : 1.21.2\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 불러오기\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"PyTorch Version :\", torch.__version__, \"\\n\")\n",
    "print(\"Numpy Version :\", np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c24ba6-b869-4864-a5a1-5a0cba705612",
   "metadata": {},
   "source": [
    "## 텐서(Tensor) 초기화\n",
    "\n",
    "- 텐서는 여러가지 방법으로 초기화할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bf2723-da32-4158-bf12-261a81e1780a",
   "metadata": {},
   "source": [
    "### 1. 데이터로부터 직접 생성하기\n",
    "\n",
    "- 데이터로부터 직접 텐서를 생성할 수 있다.\n",
    "\n",
    "- 데이터의 자료형(data type)은 자동으로 유추한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8644d28f-d60c-4882-af2b-6dd2b5b38fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [[1, 2], [3, 4]]\n",
    "\n",
    "# 'tensor' 함수를 사용하여 텐서 생성\n",
    "x_data = torch.tensor(data)\n",
    "display(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0aed0f-0678-42d0-a3dd-fd3b98093819",
   "metadata": {},
   "source": [
    "### 2. Numpy 배열로부터 생성하기\n",
    "\n",
    "- 텐서는 Numpy 배열로 생성할 수 있다. (그 반대도 가능하다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7239972e-78bc-4b0c-97b1-9a7b60b7f6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "\n",
    "x_np = torch.from_numpy(np_array)\n",
    "display(x_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a82e77-9235-47bb-a167-61ba577a72e2",
   "metadata": {},
   "source": [
    "### 3. 다른 텐서로부터 생성하기\n",
    "\n",
    "- 명시적으로 재정의(override) 하지 않는다면, 인자로 주어진 텐서의 속성(모양(shape), 자료형(datatype))을 유지한다.\n",
    "\n",
    "- 인자로 주어지는 값이 텐서 자료형이어야 하며, 텐서 자료형이 아닌 경우에는 오류가 발생한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "475f4b2d-45d1-4a90-a7d3-ab70c76b7466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor : \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor : \n",
      " tensor([[0.7065, 0.1942],\n",
      "        [0.7657, 0.9805]])\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data)\n",
    "print(f\"Ones Tensor : \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype = torch.float)\n",
    "print(f\"Random Tensor : \\n {x_rand}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "028e689a-c940-4171-a11a-9383ad434732",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ones_like(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 텐서 자료형을 입력하지 않는 경우는 오류 발생\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: ones_like(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "# 텐서 자료형을 입력하지 않는 경우는 오류 발생\n",
    "torch.ones_like(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8fd513-d166-4b55-90ff-e2dea90a0587",
   "metadata": {},
   "source": [
    "### 4. 무작위(random) 또는 상수(constant) 값을 사용하기\n",
    "\n",
    "- `shape`은 텐서의 차원(dimension)을 나타내는 튜플로, 아래 함수들에서는 출력 텐서의 차원을 입력해주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d3741f8-ba20-451d-9026-b981e08d819a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor : \n",
      " tensor([[0.1949, 0.1711, 0.1165],\n",
      "        [0.4305, 0.9235, 0.1772]]) \n",
      "\n",
      "Ones Tensor : \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor : \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2, 3,)\n",
    "\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor : \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor : \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor : \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a46dda2-332e-4d82-930f-a0afa8274d39",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad518da8-da28-4fea-aa85-37d5194c4c26",
   "metadata": {},
   "source": [
    "## 텐서의 속성(Attribute)\n",
    "\n",
    "- 텐서의 속성은 텐서의 모양(shape), 자료형(datatype) 및 어느 장치에 저장되는지를 나타낸다.\n",
    "\n",
    "- `tensor.shape` : 텐서의 모양\n",
    "\n",
    "- `tensor.dtype` : 텐서의 자료형\n",
    "\n",
    "- `tensor.device` : 텐서의 저장 위치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "78de7243-40fb-4b58-91ab-b6b6cb3d638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor : torch.Size([3, 4]) \n",
      "\n",
      "Datatype of tensor : torch.float32 \n",
      "\n",
      "Device tensor is stored on : cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3, 4)\n",
    "\n",
    "print(f\"Shape of tensor : {tensor.shape} \\n\")\n",
    "print(f\"Datatype of tensor : {tensor.dtype} \\n\")\n",
    "print(f\"Device tensor is stored on : {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb81716-3ae0-4f66-81be-f9662b5fe33b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3214133a-14e5-4fdc-bdb5-ef1d1fc5a7bc",
   "metadata": {},
   "source": [
    "## 텐서 연산(Operation)\n",
    "\n",
    "- 전치(transposing), 인덱싱(indexing), 슬라이싱(slicing), 수학 계산, 선형 대수, 임의 샘플링(random sampling) 등 100가지 이상의 텐서 연산들은 [여기](https://pytorch.org/docs/stable/torch.html)에서 확인할 수 있다.\n",
    "\n",
    "- 각 연산들은 GPU 에서도 실행할 수 있다.\n",
    "\n",
    "- 기본적으로 텐서는 CPU에 생성된다.\n",
    "\n",
    "- `.to` 메소드를 사용하면(GPU의 가용성을 확인한 뒤) GPU로 텐서를 명시적으로 이동할 수 있다.\n",
    "\n",
    "- 장치들 간에 큰 텐서들을 복사하는 것은 시간과 메모리 측면에서 비용이 많이든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c9054ee3-39b1-4c2d-90c9-d12d5623b8de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# GPU가 존재하지 않음을 의미한다.\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# GPU가 존재하면 텐서를 이동\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff24353b-d51d-46c7-bf98-f3903f9e9467",
   "metadata": {},
   "source": [
    "### 1. Numpy 식의 표준 인덱싱과 슬라이싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2dc84a4-75b9-4d41-8739-21421af8fb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row : tensor([1., 1., 1., 1.]) \n",
      "\n",
      "First column : tensor([1., 1., 1., 1.]) \n",
      "\n",
      "Last column : tensor([1., 1., 1., 1.]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "\n",
    "print(\"First row :\", tensor[0], \"\\n\")\n",
    "print(\"First column :\", tensor[:, 0], \"\\n\")\n",
    "print(\"Last column :\", tensor[..., -1], \"\\n\")\n",
    "\n",
    "tensor[:, 1] = 0\n",
    "display(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025e6245-db85-4020-9462-1c51b8233f42",
   "metadata": {},
   "source": [
    "### 2. 텐서 합치기\n",
    "\n",
    "- `torch.cat`을 사용하여 **주워진 차원**에 따라 일련의 텐서를 연결할 수 있다.\n",
    "\n",
    "- `dim` 인자에 `0`을 입력하면, 열 방향으로 텐서를 연결한다.\n",
    "\n",
    "- `dim` 인자에 `1`을 입력하면, 행 방향으로 텐서를 연결한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a98fbb4b-b31b-41dc-88b5-5ea362e51603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor : torch.Size([12, 4]) \n",
      "\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 열 방향으로 텐서 합치기\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim = 0)\n",
    "\n",
    "print(\"Shape of tensor :\", t1.shape, \"\\n\")\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e77abb05-340e-4cce-9013-c14d1f5fe96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor : torch.Size([4, 12]) \n",
      "\n",
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 행 방향으로 텐서 합치기\n",
    "t2 = torch.cat([tensor, tensor, tensor], dim = 1)\n",
    "\n",
    "print(\"Shape of tensor :\", t2.shape, \"\\n\")\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc32ad1-e63f-446f-b138-2f847be1579b",
   "metadata": {},
   "source": [
    "- cat 함수를 사용할 때, 연결하고자 하는 텐서의 모양이 완전 일치할 필요는 없다.\n",
    "\n",
    "- 만약 열 방향으로 연결하고자 하는 경우에는 열이 일치하면 된다.\n",
    "\n",
    "- 만약 행 방향으로 연결하고자 하는 경우에는 행이 일치하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2e13ee50-6da8-4f54-b1be-775033a35ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor : torch.Size([10, 4]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 열 방향으로 합치기\n",
    "row_tensor = torch.zeros(6, 4)\n",
    "\n",
    "row_cat_tensor = torch.cat([tensor, row_tensor], dim = 0)\n",
    "print(\"Shape of tensor :\", row_cat_tensor.shape, \"\\n\")\n",
    "display(row_cat_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97fe2090-9f92-44e4-b3ef-953170d84ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor : torch.Size([4, 11]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 행 방향으로 합치기\n",
    "column_tensor = torch.zeros(4, 7)\n",
    "\n",
    "column_cat_tensor = torch.cat([tensor, column_tensor], dim = 1)\n",
    "print(\"Shape of tensor :\", column_cat_tensor.shape, \"\\n\")\n",
    "display(column_cat_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa9511e-2d00-43c3-ba12-567a23f72e27",
   "metadata": {},
   "source": [
    "### 3. 산술 연산(Arithmetic operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c1eae012-a865-4b82-85ea-74c279568248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 tensor : \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "y2 tensor : \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]]) \n",
      "\n",
      "y3 tensor : \n",
      " tensor([[3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [3., 3., 3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# 두 텐서 간의 행렬 곱을 계산한다.\n",
    "# y1, y2, y3은 모두 같은 값을 갖는다.\n",
    "y1 = tensor @ tensor.T\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "\n",
    "y3 = torch.rand_like(tensor)\n",
    "torch.matmul(tensor, tensor.T, out = y3)\n",
    "\n",
    "print(f\"y1 tensor : \\n {y1} \\n\")\n",
    "print(f\"y2 tensor : \\n {y2} \\n\")\n",
    "print(f\"y3 tensor : \\n {y3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4bd66e-c074-4f89-8cfe-8239586aa763",
   "metadata": {},
   "source": [
    "- y1과 y2 방식은 연산자를 사용하거나 tensor의 메서드를 사용하여 행렬 곱을 계산하였다.\n",
    "\n",
    "- y3의 경우에는 먼저 tensor를 정의해주고, torch의 `matmul` 함수를 사용하여 저장 위치를 y3로 지정해주었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f8582b86-9d52-41c9-afa4-63ce08678a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z1 tensor : \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "z2 tensor : \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "z3 tensor : \n",
      " tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 요소별 곱을 계싼한다.\n",
    "# z1, z2, z3는 모두 같은 값을 갖는다.\n",
    "z1 = tensor * tensor\n",
    "z2 = tensor.mul(tensor)\n",
    "\n",
    "z3 = torch.rand_like(tensor)\n",
    "torch.mul(tensor, tensor, out = z3)\n",
    "\n",
    "print(f\"z1 tensor : \\n {z1} \\n\")\n",
    "print(f\"z2 tensor : \\n {z2} \\n\")\n",
    "print(f\"z3 tensor : \\n {z3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdab5ff-bae6-4524-ad47-14eb3906fd90",
   "metadata": {},
   "source": [
    "### 4. 단일-요소(single-element) 텐서\n",
    "\n",
    "- 텐서의 모든 값을 하나로 집계(aggregate)하여 요소가 하나인 텐서의 경우, `item()`을 사용하여 Python 숫자 값으로 변환할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "02d576d6-366c-45d2-8203-58a6b7bbc753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg = tensor.sum()\n",
    "agg_item = agg.item()\n",
    "\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7844119c-674d-4918-9117-f4fdbedec7c7",
   "metadata": {},
   "source": [
    "### 5. 바꿔치기(in-place) 연산\n",
    "\n",
    "- 연산 결과를 피연산자에 저장하는 연산을 바꿔치기 연산이라고 부르며, `_` 접미사를 갖는다.\n",
    "\n",
    "- 예를 들어: `x.copy_(y)` 나 `x.t_()`는 `x`를 변경한다.\n",
    "\n",
    "- `바꿔치기 연산은 메모리를 일부 절약하지만, 기록이 즉시 삭제되어 도함수 계산에 문제가 발생할 수 있다. 따라서, 사용을 권장하지 않는다.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bfefe5fb-3a71-4990-bcfb-e10bd7743023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]]) \n",
      "\n",
      "tensor([[6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.],\n",
      "        [6., 5., 6., 6.]])\n"
     ]
    }
   ],
   "source": [
    "print(tensor, \"\\n\")\n",
    "\n",
    "tensor.add_(5)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdd671b-4613-4922-becc-67107ae024a4",
   "metadata": {},
   "source": [
    "## Numpy 변환\n",
    "\n",
    "- CPU 상의 텐서와 Numpy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "aaf54e3b-aa5c-4f09-a01d-0576d232febc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : tensor([1., 1., 1., 1., 1.]) \n",
      "\n",
      "n : [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(5)\n",
    "print(f\"t : {t} \\n\")\n",
    "\n",
    "n = t.numpy()\n",
    "print(f\"n : {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c129d268-3752-46b8-861e-39bd55eeeab0",
   "metadata": {},
   "source": [
    "- 메모리 공간을 공유하고 있기 때문에, 텐서의 변경 사항이 Numpy 배열에 반영된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "498686bc-9ffe-4a3f-86d0-9a14a4ea40f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : tensor([2., 2., 2., 2., 2.]) \n",
      "\n",
      "n : [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "t.add_(1)\n",
    "\n",
    "print(f\"t : {t} \\n\")\n",
    "print(f\"n : {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f1c7d2-93b8-44bc-af22-07c67bf6cefe",
   "metadata": {},
   "source": [
    "### 1. Numpy 배열을 텐서로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3c3654aa-0eb2-4331-8d71-cea1221a8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d361af1c-c6d1-47cf-9598-612fc22bc113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : tensor([2., 2., 2., 2., 2.], dtype=torch.float64) \n",
      "\n",
      "n : [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "np.add(n, 1, out = n)\n",
    "\n",
    "print(f\"t : {t} \\n\")\n",
    "print(f\"n : {n}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
